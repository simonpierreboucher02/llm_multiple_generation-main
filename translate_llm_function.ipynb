{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee65a440-9b1c-4293-9653-ae6c6c4d1374",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    display: block;\n",
    "    padding: 12px 20px;\n",
    "    background-color: #1A73E8;\n",
    "    color: white;\n",
    "    border-radius: 30px;\n",
    "    font-family: 'Helvetica Neue', Arial, sans-serif;\n",
    "    font-size: 16px;\n",
    "    font-weight: 600;\n",
    "    margin: 15px auto;\n",
    "    width: fit-content;\n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
    "    text-align: center;\n",
    "    letter-spacing: 0.5px;\n",
    "\">\n",
    "    <strong>Translate with Various AI Models</strong>\n",
    "</div>\n",
    "\n",
    "<div style=\"\n",
    "    display: block;\n",
    "    padding: 12px 20px;\n",
    "    background-color: #66BB6A;\n",
    "    color: white;\n",
    "    border-radius: 30px;\n",
    "    font-family: 'Helvetica Neue', Arial, sans-serif;\n",
    "    font-size: 16px;\n",
    "    font-weight: 600;\n",
    "    margin: 15px auto;\n",
    "    width: fit-content;\n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
    "    text-align: center;\n",
    "    letter-spacing: 0.5px;\n",
    "\">\n",
    "    <strong>Simon-Pierre Boucher</strong>\n",
    "</div>\n",
    "\n",
    "<div style=\"\n",
    "    display: block;\n",
    "    padding: 12px 20px;\n",
    "    background-color: #FFA726;\n",
    "    color: white;\n",
    "    border-radius: 30px;\n",
    "    font-family: 'Helvetica Neue', Arial, sans-serif;\n",
    "    font-size: 16px;\n",
    "    font-weight: 600;\n",
    "    margin: 15px auto;\n",
    "    width: fit-content;\n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
    "    text-align: center;\n",
    "    letter-spacing: 0.5px;\n",
    "\">\n",
    "    <strong>2024-09-14</strong>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb0d888-26da-44aa-87ab-78d2907c7a66",
   "metadata": {},
   "source": [
    "This Python script translates a given text from one language to another using multiple models provided by OpenAI, Anthropic, and Mistral APIs. Here's a detailed explanation of its components:\n",
    "\n",
    "### 1. **Environment Setup**:\n",
    "   - **`load_dotenv()`**: Loads environment variables from a `.env` file, including API keys for OpenAI, Anthropic, and Mistral, enabling secure access to their respective APIs.\n",
    "\n",
    "### 2. **Translation Functions**:\n",
    "   - **`openai_translate_text()`**:\n",
    "     - This function sends a translation request to OpenAIâ€™s models (e.g., `gpt-4`).\n",
    "     - The prompt specifies the source and target languages and includes the text to be translated.\n",
    "     - It returns the translated text or an error message if the request fails.\n",
    "\n",
    "   - **`anthropic_translate_text()`**:\n",
    "     - Similar to the OpenAI function, this sends a request to the Anthropic API (e.g., `claude-3-5-sonnet`) to translate the provided text from one language to another.\n",
    "     - The function formats the request and returns the translation generated by the model.\n",
    "\n",
    "   - **`run_mistral()`**:\n",
    "     - This is a helper function that sends user input (in this case, the translation request) to the Mistral API for processing.\n",
    "     - It manages the API request and returns the translation generated by the model.\n",
    "\n",
    "   - **`mistral_translate_text()`**:\n",
    "     - This function builds the translation task for the Mistral API and calls `run_mistral()` to generate the translation.\n",
    "\n",
    "### 3. **Aggregated Translation**:\n",
    "   - **`translate_text_with_all_models()`**:\n",
    "     - This function iterates over lists of models from OpenAI, Anthropic, and Mistral, sending translation requests for the same text.\n",
    "     - It stores the translation results from each model in a dictionary, with the model names as keys and the translated text as values.\n",
    "     - The function processes multiple models from each API and gathers their outputs.\n",
    "\n",
    "### 4. **Main Program Execution**:\n",
    "   - **API Keys and Input Text**:\n",
    "     - The API keys are loaded from the environment variables.\n",
    "     - The text to be translated (about polar bears and climate change) is provided, along with the source language (`English`) and target language (`French`).\n",
    "\n",
    "   - **Model Lists**:\n",
    "     - Lists of models for OpenAI (`gpt-3.5-turbo`, `gpt-4`), Anthropic (`claude-3-5-sonnet`, `claude-3-opus`), and Mistral (`open-mistral-7b`, `mistral-medium-latest`) are defined for translation evaluation.\n",
    "\n",
    "   - **Generating Translations**:\n",
    "     - The function `translate_text_with_all_models()` is called to generate translations from all the models for the same input text.\n",
    "   \n",
    "   - **Results Output**:\n",
    "     - The script prints the translated results from each model, including the model name and word count of the translated text.\n",
    "\n",
    "### Purpose:\n",
    "This script is useful for comparing how different AI models from OpenAI, Anthropic, and Mistral handle translation tasks. By running the same translation task across multiple models, it allows users to evaluate and benchmark the quality and performance of each model for translation from English to French."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9614f38c-7394-4e68-a4f2-3bf52e327c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simon-pierreboucher/Desktop/notebook/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Charger les variables d'environnement\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26bbe21e-06bf-421d-a62a-0d13e49fdb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_translate_text(api_key, text, source_lang, target_lang, model=\"gpt-4\", temperature=0.7, max_tokens=1024, stop=None):\n",
    "    \"\"\"\n",
    "    Translates a given text from source language to target language using the OpenAI API.\n",
    "    \"\"\"\n",
    "    task_description = f\"Translate the following text from {source_lang} to {target_lang}.\"\n",
    "\n",
    "    prompt_content = f\"\"\"\n",
    "    {task_description}\n",
    "\n",
    "    Text: {text}\n",
    "    Translation:\n",
    "    \"\"\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt_content}\n",
    "        ],\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens\n",
    "    }\n",
    "    \n",
    "    if stop:\n",
    "        data[\"stop\"] = stop\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, data=json.dumps(data))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        translated_text = response_json[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        return translated_text\n",
    "    else:\n",
    "        return f\"Error {response.status_code}: {response.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a591adb-4849-411e-950b-a99f2f63e76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anthropic_translate_text(api_key, text, source_language, target_language, model=\"claude-3-5-sonnet-20240620\", max_tokens=1024, temperature=0.7):\n",
    "    \"\"\"\n",
    "    Translates a given text from a source language to a target language using the Anthropic API.\n",
    "    \"\"\"\n",
    "    url = \"https://api.anthropic.com/v1/messages\"\n",
    "    \n",
    "    headers = {\n",
    "        \"x-api-key\": api_key,\n",
    "        \"anthropic-version\": \"2023-06-01\",\n",
    "        \"content-type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": f\"Please translate the following text from {source_language} to {target_language}:\\n\\n{text}\"}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        translated_text = response_json[\"content\"][0][\"text\"].strip()\n",
    "        return translated_text\n",
    "    else:\n",
    "        return f\"Error {response.status_code}: {response.text}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d2b9e66-0300-4022-977d-05689159a1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mistral(api_key, user_message, model=\"mistral-medium-latest\"):\n",
    "    url = \"https://api.mistral.ai/v1/chat/completions\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ],\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 1.0,\n",
    "        \"max_tokens\": 512,\n",
    "        \"stream\": False,\n",
    "        \"safe_prompt\": False,\n",
    "        \"random_seed\": 1337\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        return response_json[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    else:\n",
    "        return f\"Error {response.status_code}: {response.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15203cd5-a0b2-40d1-b493-33ff2cb67016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mistral_translate_text(api_key, text, source_lang, target_lang, model=\"mistral-medium-latest\"):\n",
    "    \"\"\"\n",
    "    Translates a given text from source language to target language using the Mistral API.\n",
    "    \"\"\"\n",
    "    user_message = f\"Translate the following text from {source_lang} to {target_lang}:\\n\\n{text}\"\n",
    "    return run_mistral(api_key, user_message, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e91e860-ddb1-460e-9543-e6769539f12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text_with_all_models(openai_key, anthropic_key, mistral_key, text, source_lang, target_lang, openai_models, anthropic_models, mistral_models, temperature=0.7, max_tokens=100, stop=None):\n",
    "    results = {}\n",
    "\n",
    "    # Traduire du texte avec tous les modÃ¨les OpenAI\n",
    "    for model in openai_models:\n",
    "        openai_result = openai_translate_text(openai_key, text, source_lang, target_lang, model, temperature, max_tokens, stop)\n",
    "        results[f'openai_{model}'] = openai_result\n",
    "\n",
    "    # Traduire du texte avec tous les modÃ¨les Anthropic\n",
    "    for model in anthropic_models:\n",
    "        anthropic_result = anthropic_translate_text(anthropic_key, text, source_lang, target_lang, model, max_tokens, temperature)\n",
    "        results[f'anthropic_{model}'] = anthropic_result\n",
    "\n",
    "    # Traduire du texte avec tous les modÃ¨les Mistral\n",
    "    for model in mistral_models:\n",
    "        mistral_result = mistral_translate_text(mistral_key, text, source_lang, target_lang, model)\n",
    "        results[f'mistral_{model}'] = mistral_result\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aaea593-737e-4087-a19d-999ed5c7f988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mResult from openai_gpt-3.5-turbo (38 words):\u001b[0m\n",
      "Les ours polaires sont de plus en plus menacÃ©s par le changement climatique. Alors que la glace de l'Arctique fond, leur habitat diminue, ce qui rend difficile pour eux de chasser les phoques, leur principale source de nourriture.\n",
      "\n",
      "\u001b[1mResult from openai_gpt-4 (37 words):\u001b[0m\n",
      "Les ours polaires sont de plus en plus menacÃ©s par le changement climatique. Avec la fonte de la glace arctique, leur habitat se rÃ©duit, rendant difficile pour eux la chasse aux phoques, leur principale source de nourriture.\n",
      "\n",
      "\u001b[1mResult from openai_gpt-4-turbo (37 words):\u001b[0m\n",
      "Les ours polaires sont de plus en plus menacÃ©s par le changement climatique. Ã€ mesure que la glace arctique fond, leur habitat se rÃ©duit, rendant difficile pour eux de chasser les phoques, leur principale source de nourriture.\n",
      "\n",
      "\u001b[1mResult from openai_gpt-4o-mini (35 words):\u001b[0m\n",
      "Les ours polaires sont de plus en plus menacÃ©s par le changement climatique. Ã€ mesure que la glace arctique fond, leur habitat se rÃ©duit, rendant difficile la chasse aux phoques, leur principale source de nourriture.\n",
      "\n",
      "\u001b[1mResult from openai_gpt-4o (37 words):\u001b[0m\n",
      "Les ours polaires sont de plus en plus menacÃ©s par le changement climatique. Ã€ mesure que la glace arctique fond, leur habitat rÃ©trÃ©cit, ce qui leur rend difficile la chasse aux phoques, leur principale source de nourriture.\n",
      "\n",
      "\u001b[1mResult from anthropic_claude-3-5-sonnet-20240620 (44 words):\u001b[0m\n",
      "Here's the translation of the text from English to French:\n",
      "\n",
      "Les ours polaires sont de plus en plus menacÃ©s par le changement climatique. Ã€ mesure que la glace arctique fond, leur habitat rÃ©trÃ©cit, rendant difficile la chasse aux phoques, leur principale source de nourriture.\n",
      "\n",
      "\u001b[1mResult from anthropic_claude-3-opus-20240229 (44 words):\u001b[0m\n",
      "Here is the translation in French:\n",
      "\n",
      "Les ours polaires sont de plus en plus menacÃ©s par le changement climatique. Ã€ mesure que la glace de l'Arctique fond, leur habitat se rÃ©duit, rendant difficile pour eux la chasse aux phoques, leur principale source de nourriture.\n",
      "\n",
      "\u001b[1mResult from anthropic_claude-3-sonnet-20240229 (46 words):\u001b[0m\n",
      "Voici la traduction en franÃ§ais :\n",
      "\n",
      "Les ours polaires sont de plus en plus menacÃ©s par le changement climatique. Au fur et Ã  mesure que la glace arctique fond, leur habitat se rÃ©duit, rendant difficile pour eux de chasser les phoques, leur principale source de nourriture.\n",
      "\n",
      "\u001b[1mResult from anthropic_claude-3-haiku-20240307 (43 words):\u001b[0m\n",
      "Voici la traduction en franÃ§ais :\n",
      "\n",
      "Les ours polaires sont de plus en plus menacÃ©s par le changement climatique. Alors que la glace arctique fond, leur habitat se rÃ©trÃ©cit, ce qui leur rend difficile la chasse des phoques, leur principale source de nourriture.\n",
      "\n",
      "\u001b[1mResult from mistral_open-mistral-7b (40 words):\u001b[0m\n",
      "Les ours polaires sont de plus en plus menacÃ©s par le changement climatique. A mesure que la glace de l'Arctique fond, leur habitat se rÃ©duit, ce qui rend difficile pour eux de chasser les phoques, leur source de nourriture principale.\n",
      "\n",
      "\u001b[1mResult from mistral_open-mixtral-8x7b (35 words):\u001b[0m\n",
      "Les ours polaires sont de plus en plus menacÃ©s par le changement climatique. Alors que la glace de l'Arctique fond, leur habitat se rÃ©duit, ce qui complique la chasse aux phoques, leur principale source d'alimentation.\n",
      "\n",
      "\u001b[1mResult from mistral_open-mixtral-8x22b (80 words):\u001b[0m\n",
      "Les ours polaires sont de plus en plus menacÃ©s par le changement climatique. Ã€ mesure que la glace de l'Arctique fond, leur habitat se rÃ©duit, rendant difficile pour eux de chasser les phoques, leur principale source de nourriture.\n",
      "\n",
      "Traduction alternative :\n",
      "Les ours polaires sont de plus en plus menacÃ©s par les changements climatiques. Ã€ mesure que la glace de l'Arctique fond, leur habitat diminue, ce qui rend difficile pour eux de chasser les phoques, leur principale source de nourriture.\n",
      "\n",
      "\u001b[1mResult from mistral_mistral-small-latest (37 words):\u001b[0m\n",
      "Les ours polaires sont de plus en plus menacÃ©s par le changement climatique. Ã€ mesure que la banquise arctique fond, leur habitat se rÃ©duit, rendant difficile pour eux de chasser les phoques, leur principale source de nourriture.\n",
      "\n",
      "\u001b[1mResult from mistral_mistral-medium-latest (39 words):\u001b[0m\n",
      "Les ours polaires sont de plus en plus menacÃ©s par le changement climatique. Ã€ mesure que la glace arctique fond, leur habitat se rÃ©trÃ©cit, ce qui rend difficile pour eux de chasser les phoques, leur source de nourriture principale.\n",
      "\n",
      "\u001b[1mResult from mistral_mistral-large-latest (39 words):\u001b[0m\n",
      "Les ours polaires sont de plus en plus menacÃ©s par le changement climatique. Alors que la glace de l'Arctique fond, leur habitat se rÃ©duit, ce qui rend difficile pour eux la chasse aux phoques, leur principale source de nourriture.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\t\n",
    "if __name__ == \"__main__\":\n",
    "    openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    anthropic_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    mistral_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "    text_to_translate = \"Polar bears are increasingly threatened by climate change. As the Arctic ice melts, their habitat shrinks, making it difficult for them to hunt seals, their primary food source.\"\n",
    "    source_lang = \"English\"\n",
    "    target_lang = \"French\"\n",
    "\n",
    "    openai_models = [\"gpt-3.5-turbo\", \"gpt-4\", \"gpt-4-turbo\", \"gpt-4o-mini\", \"gpt-4o\"]\n",
    "    anthropic_models = [\"claude-3-5-sonnet-20240620\", \"claude-3-opus-20240229\", \"claude-3-sonnet-20240229\", \"claude-3-haiku-20240307\"]\n",
    "    mistral_models = [\"open-mistral-7b\", \"open-mixtral-8x7b\", \"open-mixtral-8x22b\", \"mistral-small-latest\", \"mistral-medium-latest\", \"mistral-large-latest\"]\n",
    "\n",
    "    results = translate_text_with_all_models(openai_key, anthropic_key, mistral_key, text_to_translate, source_lang, target_lang, openai_models, anthropic_models, mistral_models)\n",
    "    \n",
    "    for model_name, result in results.items():\n",
    "        word_count = len(result.split())\n",
    "        print(f\"\\033[1mResult from {model_name} ({word_count} words):\\033[0m\\n{result}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
